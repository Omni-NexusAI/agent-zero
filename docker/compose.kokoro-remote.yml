# Remote Kokoro GPU worker stack
# --------------------------------
# Layer this file with either docker-compose-dev.yml or docker-compose-test.yml
# to launch a lightweight GPU worker container alongside the main Agent Zero
# container:
#
#   docker compose -f docker-compose-dev.yml -f docker/compose.kokoro-remote.yml up -d
#
# The primary container will continue running on CPU while the worker consumes
# the GPU for Kokoro requests.

services:
  kokoro-gpu-worker:
    build:
      context: .
      dockerfile: docker/Dockerfile.kokoro
    command: ["python", "python/services/kokoro_gpu_worker.py"]
    working_dir: /app
    environment:
      - KOKORO_DEVICE=cuda:auto
      - KOKORO_HOST=0.0.0.0
      - KOKORO_PORT=8891
      # Uncomment to enforce token auth:
      # - KOKORO_WORKER_TOKEN=super-secret-token
    ports:
      - "8891:8891"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]



